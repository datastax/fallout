buildscript {
    dependencies {
        classpath 'guru.nidi:graphviz-java:0.8.3'
        classpath 'net.sourceforge.plantuml:plantuml:1.2019.7'
    }
}

plugins {
    id 'java'

    // This is both a library _and_ an application
    id 'java-library'
    id 'application'

    id 'jacoco'
    id "org.jetbrains.gradle.plugin.idea-ext" version "0.10"

    id "com.datastax.fallout.symlinks"
    id "com.datastax.fallout.externaltools"
    id "com.datastax.fallout.conventions.test"
    id "com.datastax.fallout.conventions.common-root-project"

    id "com.github.johnrengelman.shadow" version "6.1.0"
    id "com.github.johnrengelman.processes" version "0.5.0"
    id "com.github.voplex95.lesscompiler" version "1.0.3"
    id "com.diffplug.spotless" version "5.11.0"

    // Do not use version 10.0.0 in groovy-based build.gradle scripts
    // because of https://github.com/JLLeitschuh/ktlint-gradle/issues/443
    // We use ktlint-gradle instead of spotless ktlint support mainly
    // because of https://github.com/diffplug/spotless/issues/142
    id "org.jlleitschuh.gradle.ktlint" version "9.4.1"

    id "de.undercouch.download" version "4.1.1"
    id "com.google.osdetector" version "1.6.2"

    // This appears to be the only assertj plugin that:
    // - handles dependencies correctly;
    // - generates a single entrypoint class;
    // - can generate assertions for non-project classes.
    id "com.github.carlobellettini.assertj-generator-gradle-plugin-p" version "1.0"
}

import com.github.jengelman.gradle.plugins.processes.tasks.Fork
import static com.datastax.fallout.gradle.Utils.camelCase

group = 'com.datastax'
version = '0.1.0-SNAPSHOT'
mainClassName = 'com.datastax.fallout.service.FalloutService'

def javaModuleJvmArgs = [
    // Handle jackson reflection under Java 9+ (see
    // https://github.com/FasterXML/jackson-modules-base/issues/37#issuecomment-389581245)
    '--illegal-access=permit',
    '--add-opens', 'java.base/java.lang=ALL-UNNAMED',
    '--add-opens', 'java.base/java.nio=ALL-UNNAMED'
]

// This will be inserted into the fallout wrapper script
applicationDefaultJvmArgs = [
    '-XX:+HeapDumpOnOutOfMemoryError',
    '-XX:-OmitStackTraceInFastThrow',
    '-server',
    '-ea',
    '-Djava.util.concurrent.ForkJoinPool.common.parallelism=1024'
] + javaModuleJvmArgs

// In production, falloutctl sets heap sizes; when running within gradle
// we must set something larger than the default 512m
// (https://docs.gradle.org/current/userguide/build_environment.html#sec:configuring_jvm_memory)
// for the test and server processes:
ext.applicationGradleJvmArgs = applicationDefaultJvmArgs + ["-Xmx10G"]

description = """DataStax Fallout"""

def defaultPropertyValue(name, value) {
    if (!ext.has(name)) {
        ext.set(name, value)
    }
    ext.get(name)
}

allprojects {
    sourceCompatibility = 11.0
    targetCompatibility = 11.0
    tasks.withType(JavaCompile) {
        options.encoding = 'UTF-8'
        if (rootProject.hasProperty('showJavaCompilerWarnings')) {
            options.compilerArgs += ['-Xlint:deprecation', '-Xlint:unchecked']
        }
    }

    // Ensure that archive tasks have reproducible outputs: this allows
    // build caching and build avoidance.  See
    // https://docs.gradle.org/5.6.3/userguide/working_with_files.html#sec:reproducible_archives
    tasks.withType(AbstractArchiveTask) {
        preserveFileTimestamps = false
        reproducibleFileOrder = true
    }

    tasks.withType(Zip) {
        zip64 = true
    }

    tasks.withType(JavaExec) {
        enableAssertions = true
    }
}

def dropwizardVersion = '2.0.18'
// see https://github.com/dropwizard/dropwizard/blob/v2.0.18/dropwizard-dependencies/pom.xml#L49-L51 for dependency versions below
// Make sure the following versions are the same that dropwizard uses:
def jettyVersion = '9.4.35.v20201120'
def jerseyVersion = '2.32'
def jacksonVersion = '2.10.5'

def autoServiceVersion = '1.0-rc7'
def autoValueVersion = '1.7.5'

// Used by jepsen as well, so we define this at the project level
ext.jschVersion = "0.1.55"
def jschAgentProxyVersion = "0.0.9"

defaultTasks ':shadowJar'

sourceSets {
    testBase
    cassandraAllShaded
}

configurations {
    testBaseImplementation.extendsFrom(implementation)

    testImplementation.extendsFrom(testBaseImplementation)
    testRuntimeOnly.extendsFrom(testBaseRuntimeOnly)
    testCompileOnly.extendsFrom(testBaseCompileOnly)
}

// Make the following sourceSets available
// for consumption as feature variants; see
// https://docs.gradle.org/current/userguide/cross_project_publications.html#sec:variant-aware-sharing
java {
    registerFeature("testBase") {
        usingSourceSet(sourceSets.testBase)
    }
    registerFeature("test") {
        usingSourceSet(sourceSets.test)
    }
    registerFeature("cassandraAllShaded") {
        usingSourceSet(sourceSets.cassandraAllShaded)
    }
}

dependencies {
    api project(path: ':cassandra-all-shaded', configuration: 'shadow')
    api project(path: ':jepsen', configuration: 'shadow')

    cassandraAllShadedApi project(path: ':cassandra-all-shaded', configuration: 'shadow')

    api "com.google.guava:guava:28.2-jre"
    api "com.github.spullara.mustache.java:compiler:0.9.6"
    api "io.dropwizard:dropwizard-core:${dropwizardVersion}"
    implementation("io.dropwizard:dropwizard-views-mustache:${dropwizardVersion}") {
        exclude(group: 'com.github.spullara.mustache.java', module: 'compiler')
    }
    implementation "io.dropwizard:dropwizard-assets:${dropwizardVersion}"
    api "io.dropwizard:dropwizard-auth:${dropwizardVersion}"
    api "io.dropwizard:dropwizard-logging:${dropwizardVersion}"
    api "io.dropwizard:dropwizard-metrics-graphite:${dropwizardVersion}"
    implementation "org.eclipse.jetty:jetty-rewrite:${jettyVersion}"
    implementation "com.jcraft:jsch:${jschVersion}"
    implementation "com.jcraft:jsch.agentproxy.jsch:${jschAgentProxyVersion}"
    implementation "com.jcraft:jsch.agentproxy.sshagent:${jschAgentProxyVersion}"
    implementation "com.jcraft:jsch.agentproxy.usocket-jna:${jschAgentProxyVersion}"
    implementation "commons-io:commons-io:2.5"
    implementation "org.yaml:snakeyaml:1.28"
    implementation "com.h2database:h2:1.4.195"
    implementation "javax.mail:javax.mail-api:1.6.0"
    implementation "com.sun.mail:javax.mail:1.6.0"
    api "org.apache.commons:commons-csv:1.5"
    api "org.hdrhistogram:HdrHistogram:2.1.12"
    api 'com.github.pingtimeout:HdrLogProcessing:input-stream-instead-of-file-SNAPSHOT'
    api "io.netty:netty-all:4.1.63.Final"
    implementation "com.fasterxml.jackson.core:jackson-annotations:${jacksonVersion}"
    implementation "org.apache.httpcomponents:httpclient:4.5.13"
    implementation "org.apache.commons:commons-math3:3.6.1"

    implementation("io.dropwizard:dropwizard-views-freemarker:${dropwizardVersion}")

    // See https://github.com/smoketurner/dropwizard-swagger/releases
    //
    // Waiting for fix of
    // https://github.com/smoketurner/dropwizard-swagger/issues/210 be
    // released before we move any higher than 2.0.0-1.  Once that has
    // been done, remove DropWizard2SwaggerBundle from the source code,
    // and the constraint on io.swagger:swagger-jersey2-jaxrs:1.5.0.
    implementation ("com.smoketurner:dropwizard-swagger:2.0.0-1")
    constraints {
        implementation('io.swagger:swagger-jersey2-jaxrs') {
            version {
                strictly '1.5.13'
            }
            because 'later versions bring in reflections 0.9.11, triggering ' +
                'https://github.com/smoketurner/dropwizard-swagger/issues/171 ' +
                '(fixed in com.smoketurner:dropwizard-swagger:2.0.12-1)'
        }
    }

    // For Server-Sent Events
    implementation "org.glassfish.jersey.media:jersey-media-sse:${jerseyVersion}"
    implementation("org.glassfish.jersey.security:oauth2-client:${jerseyVersion}") {
        // Prevent the Jersey JacksonFeature (which overrides the Dropwizard
        // one) from being found and registered.
        // See https://github.com/dropwizard/dropwizard/issues/1341
        exclude(group: "org.glassfish.jersey.media", module: "jersey-media-json-jackson")
    }
    implementation "javax.ws.rs:javax.ws.rs-api:2.1.1"

    annotationProcessor "com.google.auto.service:auto-service:${autoServiceVersion}"
    testAnnotationProcessor "com.google.auto.service:auto-service:${autoServiceVersion}"
    testBaseAnnotationProcessor "com.google.auto.service:auto-service:${autoServiceVersion}"

    implementation "com.google.auto.service:auto-service-annotations:${autoServiceVersion}"

    annotationProcessor "com.google.auto.value:auto-value:${autoValueVersion}"
    implementation "com.google.auto.value:auto-value-annotations:${autoValueVersion}"

    // Compile against the main classes, but leave it up to the
    // test configuration to specify where the runtime is (test
    // will already use sourceSets.main.output by default).
    testBaseCompileOnly sourceSets.main.output

    testBaseApi platform("org.junit:junit-bom:5.7.1")
    testBaseApi "org.junit.jupiter:junit-jupiter"

    testBaseApi "org.assertj:assertj-core:3.19.0"
    testBaseApi "org.awaitility:awaitility:4.0.3"
    testBaseImplementation "io.dropwizard:dropwizard-logging:${dropwizardVersion}"
    testBaseApi("io.dropwizard:dropwizard-testing:${dropwizardVersion}") {
        exclude group: "junit", module: "junit"
    }

    testImplementation sourceSets.testBase.output
    testApi "org.apache.sshd:sshd-core:1.7.0"
    testApi "org.mockito:mockito-core:3.8.0"
    testApi 'org.mockito:mockito-junit-jupiter:3.8.0'
    testApi "org.quicktheories:quicktheories:0.26"
    testImplementation('com.github.tomakehurst:wiremock:2.27.2'){
        exclude group: 'com.fasterxml.jackson.core'
    }
    // Needed for ClojureShutdownListener
    testImplementation "org.junit.platform:junit-platform-launcher"

    implementation('com.google.cloud:google-cloud-logging:2.2.0') {
        exclude group: 'com.google.guava', module: 'guava'
    }
}

// ----------------------------------------------------------------------------
// Compilation

// Supporting @JsonCreator with implicit named parameters requires
// that we store the parameter names in the generated class files
// (https://docs.oracle.com/javase/tutorial/reflect/member/methodparameterreflection.html):
tasks.withType(JavaCompile) {
    options.compilerArgs += '-parameters'
}

// ----------------------------------------------------------------------------
// IDEA integration

idea {
    module {
        // Exclude directories that are ignored in .gitignore; this should be
        // automatic, but it isn't: see
        // https://youtrack.jetbrains.com/issue/IDEA-140714
        excludeDirs += [
            // Ignore files created by running fallout/cassandra in
            // the current directory
            file('tests'), file('cassandra'), file('run'), file('logs'),

            // Nothing creates tmp, but it's a convenient place to keep
            // temporary things
            file('tmp')
        ]
    }
}

def ideaVersion = System.getProperty('idea.version')

if (ideaVersion) {

    def (major, minor) = ideaVersion.split("\\.").collect { it.toInteger() }

    // IDEA 2019 defines idea.version for _all_ gradle invocations; prior
    // versions only defined it when importing.  2019 additionally
    // defines sync.active when importing.
    def importing = major < 2019 || System.getProperty('idea.sync.active');

    if (importing) {

        println "Detected IDEA ${ideaVersion} Sync"

        // IDEA used to incorrectly use the annotation processor classpath as
        // "Provided", which means that any library versions in the annotation
        // processor classpath override the versions in the implementation
        // classpath.  This is no longer the case in 2020.3; it may have
        // been fixed earlier
        if (major < 2020 || (major == 2020 && minor < 3)) {
            println "Fixing incorrect annotation processor classpaths"
            dependencies {
                annotationProcessor configurations.implementation
                testAnnotationProcessor configurations.testImplementation
            }
        }

        // IDEA < 2019.3 searches for annotation processors on the classpath,
        // and doesn't use the annotationProcessor configuration,
        // so we add it here.
        if (major < 2019 || (major == 2019 && minor < 3)) {
            println "Adding annotation processor classpaths"
            idea {
                module {
                    scopes.each {
                        it.value.plus += [configurations.annotationProcessor]
                    }
                }
            }
        }
    }
}

// ----------------------------------------------------------------------------
// Convenience

task compile {
    setDependsOn(tasks.findAll {
        it.name != 'compile' &&
            it.name.startsWith('compile') &&
            !it.name.startsWith('compileJenkins')
    })
}

task publish {
    group 'publish'
    description "Publish all artifacts that make up a release"
}

// ----------------------------------------------------------------------------
// Run cassandra as a standalone process

def cassandraVersion = "2.1.21"

configurations {
    cassandraStandalone
}

dependencies {
    cassandraStandalone 'org.jmxtrans.agent:jmxtrans-agent:1.2.8'
    cassandraStandalone "org.apache.cassandra:cassandra-all:${cassandraVersion}"
}

task startCassandra(type: Fork) {
    def pidFile = file("${project.rootDir}/run/cassandra.pid")
    def java8Home = System.getenv('JAVA8_HOME')
    def classPath = configurations.cassandraStandalone.asPath
    def cassandraYaml = "${project.rootDir}/src/main/resources/cassandra.yaml"
    def logbackXml = "${project.rootDir}/etc/cassandra/logback.xml"
    def logDir = "${project.rootDir}/logs/cassandra"

    doFirst {
        if (!java8Home) {
            throw new GradleException("JAVA8_HOME must be set to run startCassandra task")
        }
    }

    workingDir "${project.rootDir}"
    commandLine "${java8Home}/bin/java",
        "-classpath", classPath,
        "-XX:+HeapDumpOnOutOfMemoryError", "-Xms8G", "-Xmx8G", "-server", "-ea",
        "-Dcassandra.config=file://${cassandraYaml}",
        "-Dcassandra-pidfile=${pidFile}",
        "-Dcassandra.logdir=${logDir}",
        "-Dlogback.configurationFile=${logbackXml}",
        "org.apache.cassandra.service.CassandraDaemon"

    doLast {
        def waitSeconds = 60
        def port = 9096
        def portOpened = false

        while (!portOpened && waitSeconds && !processHandle.state.terminal) {
            try {
                new Socket("localhost", port);
                portOpened = true
            }
            catch (ConnectException e) {
            }
            waitSeconds -= 1
            Thread.sleep(1000)
        }

        if (processHandle.state.terminal) {
            throw new GradleException("Cassandra exited with code ${processHandle.waitForFinish().exitValue}")
        }

        if (!portOpened) {
            processHandle.abort()
            throw new GradleException("Cassandra didn't start listening on ${port} within ${waitSeconds} seconds")
        }
    }
}

task stopCassandra {
    doFirst {
        startCassandra.processHandle.abort()
        startCassandra.processHandle.waitForFinish()
    }
}

// ----------------------------------------------------------------------------
// General helpers

def execWithOutput(String... command) {
    def process = command.execute();
    if (process.waitFor() != 0) {
        throw new RuntimeException("'" + command + "' failed:\n" +
            "STDOUT:\n" +
            process.in.text +
            "\nSTDERR:\n" +
            process.err.text)
    }
    return process.text.trim()
}

// ----------------------------------------------------------------------------
// Version info

// We don't use grgit to do this because it doesn't support worktrees:
// https://github.com/ajoberstar/grgit/issues/97

ext {
    gitDir = null

    try {
        gitDir = execWithOutput("git", "rev-parse", "--git-dir")
    }
    catch(RuntimeException e) {
        // ignore: leave gitDir as null, indicating we are not in a repo
    }
}

def gitCommand(command) {
    // We have to specify --git-dir and --work-tree because the gradle daemon
    // doesn't unset environment variables, it just sets them to empty.  If
    // we run gradle as part of a `git -x './gradlew compile' rebase` or a
    // bisect, then GIT_WORK_TREE and GIT_DIR will be set; running outside of
    // the bisect or rebase, the two env vars will be set to empty, which
    // will cause git to fail.
    return execWithOutput((["git", "--git-dir=${gitDir}",
        "--work-tree=${rootProject.projectDir}"] + command) as String[])
}

ext {
    if (gitDir != null) {
        gitDescribe = gitCommand(["describe"])
        gitBranch = gitCommand(["rev-parse", "--abbrev-ref", "HEAD"])
        gitCommit = gitCommand(["rev-parse", "HEAD"])
        githubRepo = gitCommand(["remote", "get-url", "origin"])
            .replaceAll('^.*github.com[:/](.*?)(:?\\.git)?$', '$1')
            .toLowerCase()
    } else {
        gitDescribe = "NO_GIT_REPO"
        gitBranch = "NO_GIT_REPO"
        gitCommit = "NO_GIT_REPO"
        githubRepo = "NO_GIT_REPO"
    }
}

// ----------------------------------------------------------------------------
// Generated resources

def generatedResourcesOutputDir = file("${buildDir}/src/main/resources")

sourceSets {
    main {
        resources {
            srcDirs += generatedResourcesOutputDir
        }
    }
}

// LESS

lessCompile {
    source = file('src/main/resources/assets/less/fallout.less')

    target = file("${generatedResourcesOutputDir}/assets/css/fallout.css")

    // The lessCompile task doesn't declare inputs or outputs, so we do it here
    inputs.files fileTree('src/main/resources/assets/less')
    outputs.file target
}

processResources.dependsOn(lessCompile)

// Version HTML file

task generateVersionFile() {
    ext.target = file("${generatedResourcesOutputDir}/assets/pages/version.html")
    ext.targetContent = """
        <dl>
        <dt>branch:
        <dd><a href="https://github.com/${githubRepo}/tree/${gitBranch}">${gitBranch}</a>
        <dt>commit:
        <dd><a href="https://github.com/${githubRepo}/commit/${gitCommit}">${gitCommit}</a>
        </dl>
    """

    inputs.property("content", targetContent)
    outputs.file target

    doLast {
        target.getParentFile().mkdirs()
        target.text = targetContent
    }
}

// fallout-client installers

task generateCliInstaller() {
    ext.target = file("${generatedResourcesOutputDir}/assets/installers/cli")
    ext.targetContent = """
        pipx install --force "git+ssh://git@github.com/${githubRepo}.git@${gitCommit}#egg=fallout-client&subdirectory=fallout-cli"
    """

    inputs.property('content', targetContent)
    outputs.file target

    doLast {
        target.getParentFile().mkdirs()
        target.text = targetContent
    }
}

task generateApiInstaller() {
    ext.target = file("${generatedResourcesOutputDir}/assets/installers/api")
    ext.targetContent = """
        pip install --upgrade "git+ssh://git@github.com/${githubRepo}.git@${gitCommit}#egg=fallout-client&subdirectory=fallout-cli"
    """

    inputs.property('content', targetContent)
    outputs.file target

    doLast {
        target.getParentFile().mkdirs()
        target.text = targetContent
    }
}

processResources.dependsOn(generateVersionFile, generateCliInstaller, generateApiInstaller)

// ----------------------------------------------------------------------------
// Generated sources

def generatedSourcesOutputDir = file("${buildDir}/src/main/java")

sourceSets {
    main {
        java {
            srcDirs += generatedSourcesOutputDir
        }
    }
}

// Annotation processors

sourceSets.each { sourceSet ->
    if (sourceSet.compileJavaTaskName != null) {
        tasks[sourceSet.compileJavaTaskName].configure {
            options.annotationProcessorGeneratedSourcesDirectory =
                file("${buildDir}/src/${sourceSet.name}/java-annotation-processors")
        }
    }
}

// Internal version string

task generateVersionJavaFile {
    ext.target = file("${generatedSourcesOutputDir}/com/datastax/fallout/FalloutVersion.java")
    ext.targetContent = """
        package com.datastax.fallout;

        public class FalloutVersion {
            public static String getVersion() { return "${gitDescribe}"; }
            public static String getCommitHash() { return "${gitCommit}"; }
        }
    """

    inputs.property("content", targetContent)
    outputs.file target

    doLast {
        target.getParentFile().mkdirs()
        target.text = targetContent
    }
}

compileJava.dependsOn(generateVersionJavaFile)

// ----------------------------------------------------------------------------
// AssertJ custom assertion generation

assertjGenerator {
    classOrPackageNames = [
        'com.datastax.fallout.harness.TestResult',
        'com.datastax.fallout.ops.NodeGroup',
        'com.datastax.fallout.ops.commands.NodeResponse',
        'com.datastax.fallout.runner.CheckResourcesResult',
        'com.datastax.fallout.service.core.Test',
        'com.datastax.fallout.service.core.TestRun',
        'com.datastax.fallout.service.core.User',
        'javax.ws.rs.core.Response',
        'javax.ws.rs.core.Response$StatusType']

    entryPointPackage = "com.datastax.fallout.assertj"
    outputDir = file("${buildDir}/src/testBase/java")
    testSourceSet = sourceSets.testBase
}

// ----------------------------------------------------------------------------
// Distribution and packaging

["startScripts", "startShadowScripts"]
    .collect { tasks[it] }
    *.configure {

        // Insert FALLOUT_HOME and PATH into the default start script before
        // the final "exec" line that runs java.  It's _possible_ to work out
        // where the java executable is running from within the code, but it's more
        // involved and less reliable than doing it from the wrapper.
        doLast {
            unixScript.text = unixScript.text.replaceFirst(~'(\nexec .*\\s*$)', {
                '''
    export FALLOUT_DIST="$APP_HOME"
    export FALLOUT_HOME="${FALLOUT_HOME:-$FALLOUT_DIST}"
    export PATH="$FALLOUT_DIST/bin:$PATH"
    ''' + it[0]
            })
        }
    }

// External tools

externalTools {
    configuration("main") {
        binary("kubectl") {

            // See https://kubernetes.io/docs/tasks/tools/install-kubectl
            // for location of binaries and checksums

            platforms(["linux", "darwin"]) {
                source.set("https://dl.k8s.io/release/v1.21.0/bin/${platform}/amd64/kubectl")
            }

            platform("linux") {
                checksum.set("9f74f2fa7ee32ad07e17211725992248470310ca1988214518806b39b1dad9f0")
            }

            platform("darwin") {
                checksum.set("f9dcc271590486dcbde481a65e89fbda0f79d71c59b78093a418aa35c980c41b")
            }
        }

        tarball("kots") {
            // https://github.com/replicatedhq/kots/releases/

            platforms(["linux", "darwin"]) {
                source.set("https://github.com/replicatedhq/kots/releases/download/v1.41.1/" +
                    "kots_${platform}_amd64.tar.gz")
                symlinkName.set("kubectl-kots")
            }

            platform("linux") {
                checksum.set("e7259868190d88d5c3fcd432fb1d44a6b4dae2a032ecdfe0034c98a8bbf814a0")
            }

            platform("darwin") {
                checksum.set("d438f2ac05e0d82509f63072b1f07f686bd1f80d7b1b9663be9cf0cf09b06aba")
            }
        }

        tarball("helm") {
            // https://github.com/helm/helm/releases

            platforms(["linux", "darwin"]) {
                source.set("https://get.helm.sh/helm-v3.5.4-${platform}-amd64.tar.gz")
                unpackedBinDir.set("${platform}-amd64")
            }

            platform("linux") {
                checksum.set("a8ddb4e30435b5fd45308ecce5eaad676d64a5de9c89660b56face3fe990b318")
            }

            platform("darwin") {
                checksum.set("072c40c743d30efdb8231ca03bab55caee7935e52175e42271a0c3bc37ec0b7b")
            }
        }

        tarball("gcloud") {
            // https://console.cloud.google.com/storage/browser/cloud-sdk-release for all versions;
            // https://cloud.google.com/sdk/docs/install for current

            platforms(["linux", "darwin"]) {
                source.set("https://dl.google.com/dl/cloudsdk/channels/rapid/" +
                    "downloads/google-cloud-sdk-341.0.0-${platform}-x86_64.tar.gz")
                unpackedBinDir.set("google-cloud-sdk/bin")
            }

            platform("linux") {
                checksum.set("baafb8415d0d1c909c229ad704b1b05de57e10cddabc4fdf8018db4bcf02ab45")
            }

            platform("darwin") {
                checksum.set("e7c13e1159b9a9652b2fb96b776f73b58f145fb53e0d4c13c4cba1a6dd01b800")
            }
        }
    }

    configuration("test") {
        binary("kind") {
            // https://github.com/kubernetes-sigs/kind/releases

            platforms(["linux", "darwin"]) {
                source.set("https://kind.sigs.k8s.io/dl/v0.10.0/kind-${platform}-amd64")
            }

            platform("linux") {
                checksum.set("74767776488508d847b0bb941212c1cb76ace90d9439f4dee256d8a04f1309c6")
            }

            platform("darwin") {
                checksum.set("a934e573621917a2785f3ddfa7b6187d18fa1c20c94c013919736b3256d37f57")
            }
        }
    }
}

def currentOs = osdetector.os

defaultPropertyValue("externalTestToolsDir", "${buildDir}/externalTestTools")

["linux", "osx"].each { osName ->

    // The same as the standard distribution plus the external-tools
    distributions.create(osName) {
        contents {
            with distributions.main.contents
            from(project.externalTools.configuration("main").platform(osName).installTask)
        }
    }

    distributions.create(camelCase("shadow", osName)) {
        contents {
            with distributions.shadow.contents
            from(project.externalTools.configuration("main").platform(osName).installTask)
        }
    }
}

distributions.create("native") {
    contents {
        with distributions[currentOs].contents
    }
}

distributions.create("shadowNative") {
    contents {
        with distributions[camelCase("shadow", currentOs)].contents
    }
}

distributions.matching { dist ->
    dist.name == "main" || dist.name == "shadow"  }
    *.contents {

        // Cassandra standalone support
        from(configurations.cassandraStandalone) {
            into('lib/cassandra-standalone')
        }
        from("etc/cassandra") {
            into('lib/cassandra-standalone')
        }
        from("src/main/resources") {
            include "cassandra.yaml"
            into('lib/cassandra-standalone')
        }

        // Include the nginx config support files
        from('etc/nginx') {
            into('nginx')
        }

        // Include tool support scripts
        from('tools/support') {
            into('lib/tools/support')
        }
    }

// Include python sources for tools
subprojects { subproject ->
    subproject.afterEvaluate {
        if (subproject.ext.has('isPythonTool')) {
            distributions
                .matching { dist ->
                    dist.name == "main" || dist.name == "shadow"
                }
                *.contents {
                    from(subproject.toolContents) {
                        into "lib/tools/${subproject.toolCategory}/${subproject.toolName}"
                    }
                }
        }
    }
}

// Ensure shadowJar correctly merges all the service files and also
// caches the output (it doesn't by default)
shadowJar {
    mergeServiceFiles()

    outputs.cacheIf { true }
}

// Ensure shadowJar correctly merges all the service files and also
// caches the output (it doesn't by default)
shadowJar {
    mergeServiceFiles()

    outputs.cacheIf { true }
}

// Docker

def dockerContextDir = file("${buildDir}/docker-context")

task dockerPrepareImageFiles(type: SyncSymlinks) {
    group 'docker'

    from installShadowLinuxDist
    from file("docker/image-files")
    ext.outputDir = file("${dockerContextDir}/image-files")
    into outputDir
}

task dockerPrepare(type: Sync, dependsOn: [dockerPrepareImageFiles]) {
    group 'docker'

    from file("docker/build-files")
    into file("${dockerContextDir}/build-files")
}

task dockerBuild(type: Exec) {
    group 'docker'
    dependsOn dockerPrepare
    workingDir dockerContextDir

    // Use the latest docker buildkit to support ssh-agent proxying
    // during build
    environment "DOCKER_BUILDKIT", 1

    def name = "datastax/fallout"
    def tag = gitDescribe.replace("fallout-", "")
    ext.latestTag = "${name}:latest"
    ext.versionTag = "${name}:${tag}"

    commandLine "docker", "builder", "build",
        "--file", "build-files/Dockerfile",
        "--tag", latestTag,
        "--tag", versionTag,
        "--progress", "plain",
        "--ssh", "default",
        "."
}

defaultPropertyValue("dockerRegistry", "docker.io")

import java.nio.charset.StandardCharsets

task dockerLogin(type: Exec) {
    group 'docker'

    def DOCKER_USERNAME_PROPERTY = "dockerUsername"
    def DOCKER_PASSWORD_PROPERTY = "dockerPassword"

    description "If the gradle properties ${DOCKER_USERNAME_PROPERTY} and " +
        "${DOCKER_PASSWORD_PROPERTY} are set, then use them to login to " +
        "the docker registry"

    def dockerUsername = project.findProperty(DOCKER_USERNAME_PROPERTY) ?: ""
    def dockerPassword = project.findProperty(DOCKER_PASSWORD_PROPERTY) ?: ""

    onlyIf {
        dockerUsername && dockerPassword
    }

    standardInput = new ByteArrayInputStream(
        dockerPassword.getBytes(StandardCharsets.UTF_8))

    commandLine "docker", "login", "-u", dockerUsername, "--password-stdin", dockerRegistry
}

task dockerPush {
    group 'docker'
    description 'Push the docker image to the docker registry defined by ' +
        'the dockerRegistry gradle property'

    dependsOn dockerBuild, dockerLogin

    doLast {
        [dockerBuild.latestTag, dockerBuild.versionTag].each { tag ->
            def registryTag = "${dockerRegistry}/${tag}"

            exec {
                commandLine "docker", "image", "tag", tag, registryTag
            }
            exec {
                commandLine "docker", "image", "push", registryTag
            }
        }
    }
}

publish.dependsOn(dockerPush)

ext.dockerComposeFile = file("docker/docker-compose.yml")

task dockerComposeUp(type: Exec) {
    group 'docker'

    dependsOn("dockerBuild")
    commandLine "docker-compose", "-f", dockerComposeFile, "up", "-d"
    environment "CASSANDRA_VERSION", cassandraVersion
    if (osdetector.os == "osx") {
        environment "SSH_AUTH_SOCK", "/run/host-services/ssh-auth.sock"
    }
}

task dockerComposeDown(type: Exec) {
    group 'docker'

    commandLine "docker-compose", "-f", dockerComposeFile, "down"
}

// ----------------------------------------------------------------------------
// Tests

// Dummy rendezvous task to allow builds that compose this build to
// serialize tests
task allTestsFinished

// Pick up any and all generated coverage files
// https://github.com/gradle/gradle/issues/5898#issuecomment-554600486
jacocoTestReport {
    getExecutionData().setFrom(fileTree(buildDir).include("/jacoco/*.exec"))
}

defaultPropertyValue("testToolsRunDir", "${buildDir}/testToolsRun")

task installToolsForTesting

subprojects {
    rootProject.installToolsForTesting {
        dependsOn tasks.matching { it.name == "installToolForTesting" }
    }
}

allprojects {
    // Make sure we delete any generated coverage files before running any
    // test; if we don't, then coverage reports can include data from test
    // tasks that weren't run as part of the current gradle invocation
    task cleanJacocoOutputs(type: Delete) {
        delete jacocoTestReport.executionData
    }

    tasks.withType(Test) {
        dependsOn(
            externalTools.installAllNativeTask,
            installToolsForTesting)

        environment "PATH", "${externalTools.nativePath}:${System.getenv('PATH')}"
        environment "FALLOUT_TOOLS_DIR", "${testToolsRunDir}/tools"

        useJUnitPlatform()

        jvmArgs = project.applicationGradleJvmArgs

        if (rootProject.hasProperty('testIgnoreFailures')) {
            ignoreFailures = testIgnoreFailures.toBoolean()
        }

        [
            "runExpensiveTests",
            "runTestsThatCostMoney",
            "skipCCMTests"
        ].each { property ->
            if (rootProject.hasProperty(property)) {
                systemProperty property, true
            }
        }

        // Pass through any -Plog.... settings as system properties
        // (see LogbackConfigurator.java)
        rootProject.properties.each { k, v ->
            if (k =~ /log\..*/) {
                systemProperty k, v
            }
        }

        testLogging {
            events "skipped", "failed", "passed"
            exceptionFormat "full"
        }

        // Ensure the whole test framework uses the slf4j bridge by setting it
        // in the below properties file; if we don't do this, then there'll
        // be a period of time where the java.util.logging framework is used
        // before gradle manually installs the slf4j bridge
        systemProperties += [
            'java.util.logging.config.file':
                "${project.rootDir}/src/testBase/resources/java.util.logging.properties"
        ]

        def reportDestination = file("${buildDir}/reports/junit/${it.name}")

        reports {
            html.enabled = false
            junitXml.enabled = true
            junitXml.outputPerTestCase = true
            junitXml.destination = reportDestination
        }

        def jacocoPluginApplied = extensions.findByType(JacocoTaskExtension)
        if (jacocoPluginApplied) {

            // Generating coverage data has a non-negligible runtime cost, so we
            // don't enable it by default
            def generateCoverageData = rootProject.hasProperty('generateCoverageData')

            jacoco {
                enabled = generateCoverageData
            }

            if (generateCoverageData) {
                dependsOn cleanJacocoOutputs
                finalizedBy jacocoTestReport
            }
        }
    }
}

test {
    useJUnitPlatform {
        excludeTags "requires-db"
    }

    testClassesDirs = testClassesDirs.plus(
        sourceSets.testBase.output.classesDirs)

    finalizedBy allTestsFinished
}

task dbTest(type: Test) {
    description = 'Starts a local DB instance and runs tests marked RequiresDb.'
    group = 'verification'

    useJUnitPlatform {
        includeTags "requires-db"
    }

    dependsOn startCassandra
    finalizedBy stopCassandra, allTestsFinished

    mustRunAfter test
}

["check", "cleanCheck"].each { taskName ->
    gradle.includedBuilds.each { includedBuild ->
        tasks[taskName].dependsOn(includedBuild.task(":${taskName}"))
    }
}

// ----------------------------------------------------------------------------
// Running development versions

def nginxStandaloneDir = file("${buildDir}/nginx-standalone")

task generateStandaloneNginxFalloutYml {
    ext.falloutYml = file("fallout.yml")
    ext.generatedFalloutYml = file("${nginxStandaloneDir}/fallout.yml")

    inputs.file falloutYml
    outputs.file generatedFalloutYml

    doLast {
        generatedFalloutYml.getParentFile().mkdirs()
        generatedFalloutYml.withOutputStream { out ->
            if (falloutYml.exists()) {
                falloutYml.withInputStream {
                    out << it.filterLine {
                        !it.contains("useNginxToServeArtifacts")
                    }
                }
            }
            out << "\nuseNginxToServeArtifacts: true"
        }
    }
}

task generateStandaloneNginxConf(type: JavaExec, dependsOn: [compileJava, generateStandaloneNginxFalloutYml]) {
    ext.nginxConf = file("${nginxStandaloneDir}/nginx.conf")
    ext.nginxHtml = file("etc/nginx/html")

    outputs.file nginxConf

    main run.main
    classpath run.classpath
    args 'generate-nginx-conf',
        '--standalone',
        '--nginx-listen-port', '8090',
        '--output', nginxConf,
        generateStandaloneNginxFalloutYml.generatedFalloutYml, nginxHtml
}

task startStandaloneNginx(type: Fork, dependsOn: generateStandaloneNginxConf) {
    commandLine "nginx", "-p", nginxStandaloneDir, "-c", generateStandaloneNginxConf.nginxConf
}

task stopStandaloneNginx {
    doFirst {
        startStandaloneNginx.processHandle.abort()
    }
}

class RunServer extends JavaExec {
    RunServer() {
        main = project.tasks.run.main
        classpath = project.tasks.run.classpath
        group = "application"

        dependsOn(
            project.externalTools.installAllNativeTask,
            project.tasks.installToolsForTesting)

        environment "PATH", "${project.externalTools.nativePath}:${System.getenv('PATH')}"
        environment "FALLOUT_TOOLS_DIR", "${project.ext.testToolsRunDir}/tools"

        jvmArgs project.applicationGradleJvmArgs
        if (project.hasProperty("devmode")) {
            jvmArgs jvmArgs + ['-Dfallout.devmode=true']
        }
    }
}

task runServerWithNginx(type: RunServer) {
    description "Run the fallout server and nginx, " +
        "using nginx to serve artifacts"

    dependsOn startStandaloneNginx, startCassandra
    finalizedBy stopCassandra, stopStandaloneNginx

    args 'standalone', generateStandaloneNginxFalloutYml.generatedFalloutYml
}

task runServer(type: RunServer) {
    description "Run the fallout server"

    ext.falloutYml = file("fallout.yml")
    inputs.files falloutYml

    dependsOn startCassandra
    finalizedBy stopCassandra

    if (falloutYml.exists()) {
        args 'standalone', falloutYml
    }
    else {
        args 'standalone'
    }
}
task runServerInDocker {
    group 'docker'
    description "Run the fallout server docker image using docker-compose"

    dependsOn "dockerComposeUp"
    finalizedBy "dockerComposeDown"

    // Gradle won't run finalizers on ctrl-C, and it won't pass the
    // SIGINT thus generated to child processes (it uses destroyForcibly
    // == SIGTERM), so we can't just make this task run plain
    // "docker-compose up" and allow ctrl-C to do graceful shutdown.
    doFirst {
        println "Fallout server is running; press <RETURN> to terminate."
        println "Will start log tailing in a moment..."

        // Give people a chance to see the above message
        Thread.sleep(5000)

        def dockerComposeLogs = project.procs.fork {
            commandLine "docker-compose", "-f", dockerComposeFile, "logs", "--follow"
        }

        System.in.read();

        dockerComposeLogs.abort()
    }
}

// ----------------------------------------------------------------------------
// Create a custom jar with a different FalloutVersion for the purpose of
// deployment testing

def generatedDeploymentTestSourcesOutputDir = file("${buildDir}/src/deploymentTestVersion/java")

sourceSets {
    deploymentTest {
        java {
            srcDirs += generatedDeploymentTestSourcesOutputDir
        }
    }
}

task generateDeploymentTestVersionJavaFile {
    ext.target = file("${generatedDeploymentTestSourcesOutputDir}/com/datastax/fallout/FalloutVersion.java")
    ext.targetContent = """
        package com.datastax.fallout;

        public class FalloutVersion {
            public static String getVersion() { return "DEPLOYMENT_TEST"; }
            public static String getCommitHash() { return "DEPLOYMENT_TEST"; }
        }
    """

    inputs.property("content", targetContent)
    outputs.file target

    doLast {
        target.getParentFile().mkdirs()
        target.text = targetContent
    }
}

compileDeploymentTestJava.dependsOn(generateDeploymentTestVersionJavaFile)

// Create a jar that contains all but the FalloutVersion from the main
// sourceset, and the FalloutVersion we build for deployment testing
task deploymentTestJar(type: Jar) {
    from(sourceSets.main.output) {
        exclude "**/FalloutVersion.*"
    }
    from(sourceSets.deploymentTest.output)
    archiveFileName = "fallout-deploymentTest.jar"
}

// ----------------------------------------------------------------------------
// Cleanliness

spotless {
    java {
        custom 'prefer generated assertj entry point', { str ->
            str.replace('import static org.assertj.core.api.Assertions.',
                'import static com.datastax.fallout.assertj.Assertions. ')
        }

        // The spotless import ordering plugin is based on the eclipse one;
        // it's not as advanced as IntelliJ, in that it _always_ inserts a
        // blank line between groups, and matches imports by longest
        // matching prefix: there's no wildcard matching.
        // An empty group ('') matches everything.
        // '\\#' matches static imports.
        //
        // If you change this, you should also change the import order in
        // ij_java_imports_layout in .editorconfig.
        //
        // This ordering is pragmatic rather than anything else; it matches
        // the ordering that most of the codebase already had before we started
        // enforcing it.
        importOrder(
            'javax.', 'java.', '', 'com.datastax.', 'org.apache.cassandra.', '\\#')
        removeUnusedImports()

        endWithNewline()
        trimTrailingWhitespace()
        eclipse().configFile("eclipse-format.prefs")
        licenseHeaderFile "gradle/LicenseHeader.java"

        target "src/*/java/**/*.java"
    }
}

// This should a be a reasonably quick validation that the code is "clean"
task lint(dependsOn: [spotlessCheck, ktlintCheck, compile]) {
    gradle.includedBuilds.each { includedBuild ->
        dependsOn(includedBuild.task(":lint"))
    }
}

test {
    shouldRunAfter spotlessCheck
}

// ----------------------------------------------------------------------------
// Diagrams; we use a graphviz library to generate a PNG, and plantuml for
// sequence diagrams

import guru.nidi.graphviz.engine.Graphviz
import guru.nidi.graphviz.engine.Format

task dumpNodeGroupStatesToDot(type: JavaExec) {
    group "documentation"

    ext.dotFile = file("${buildDir}/node-group-states.dot")
    description "Create a DOT diagram of node states in ${dotFile}"

    dependsOn compileJava
    outputs.file dotFile

    main = 'com.datastax.fallout.ops.DumpNodeGroupStatesToDot'
    classpath = sourceSets.main.runtimeClasspath
    args = [dotFile]
}

def renderDotFile(dotFile, pngFile) {
    Graphviz.fromFile(dotFile).render(Format.PNG).toFile(pngFile)
}

task dumpNodeGroupStatesToPng {
    group "documentation"

    dependsOn dumpNodeGroupStatesToDot
    inputs.files dumpNodeGroupStatesToDot
    outputs.file file("docs/node-group-states.png")

    description "Create a PNG diagram of node states in " +
        "${outputs.files.singleFile}"

    doLast {
        renderDotFile(inputs.files.singleFile, outputs.files.singleFile)
    }
}

task renderDocsDots {
    group "documentation"
    description "Creates PNGs from DOT source files in docs/assets"

    inputs.files fileTree(dir: "docs/assets", include: "*.dot")
    outputs.files inputs.files.collect { f -> file(f.path.replace(".dot", ".png")) }
    doLast {
        inputs.files.each { f ->
            renderDotFile(f, file(f.path.replace(".dot", ".png")))
        }
    }
}

// I couldn't make https://github.com/cosminpolifronie/gradle-plantuml-plugin
// work as of 1.6.0, so we're hand-rolling this like the dot support above:

import net.sourceforge.plantuml.SourceStringReader
import net.sourceforge.plantuml.FileFormatOption
import net.sourceforge.plantuml.FileFormat

def renderPlantUmlFile(plantUmlFile, pngFile) {
    pngFile.withOutputStream { out ->
        new SourceStringReader(plantUmlFile.text)
            .outputImage(out, new FileFormatOption(FileFormat.PNG, true))
    }
}

task renderDocsPlantUmls {
    group "documentation"
    description "Creates PNGs from plantuml source files in docs/assets"

    inputs.files fileTree(dir: "docs/assets", include: "*.plantuml")
    outputs.files inputs.files.collect { f -> file(f.path.replace(".plantuml", ".png")) }
    doLast {
        inputs.files.each { f ->
            renderPlantUmlFile(f, file(f.path.replace(".plantuml", ".png")))
        }
    }
}

task docs(dependsOn: [dumpNodeGroupStatesToPng, renderDocsDots, renderDocsPlantUmls]) {
    group "documentation"
    description "Run all documentation tasks except javadoc"
}

// ----------------------------------------------------------------------------

wrapper {
    // https://gradle.org/release-checksums/
    gradleVersion = '6.8.3'
    distributionSha256Sum = '7faa7198769f872826c8ef4f1450f839ec27f0b4d5d1e51bade63667cbccd205'
    scriptFile = "${project.projectDir}/gradle/gradlew"
}
